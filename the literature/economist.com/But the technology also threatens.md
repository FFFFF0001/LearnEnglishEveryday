Researchers at Stanford University have demonstrated that, when shown pictures of one gay man, and one straight man, the algorithm could attribute their sexuality correctly 81% of the time.

Humans managed only 61%.

In countries where homosexuality is a crime, software which promises to infer sexuality from a face is an alarming prospect.

Less violent forms of discrimination could also become common.

Employers can already act on their prejudices to deny people a job.

But facial recognition could make such bias routine, enabling firms to filter all job applications for ethnicity and signs of intelligence and sexuality.

Nightclubs and sports grounds may face pressure to protect people by scanning entrants' faces for the threat of violence—even though, owing to the nature of machine-learning, all facial-recognition systems inevitably deal in probabilities.

Moreover, such systems may be biased against those who do not have white skin, since algorithms trained on data sets of mostly white faces do not work well with different ethnicities.

Such biases have cropped up in automated assessments used to inform courts' decisions about bail and sentencing.

Eventually, continuous facial recording and gadgets that paint computerised data onto the real world might change the texture of social interactions.

Dissembling helps grease the wheels of daily life.

If your partner can spot every suppressed yawn, and your boss every grimace of irritation, marriages and working relationships will be more truthful, but less harmonious.

Start with privacy.

One big difference between faces and other biometric data, such as fingerprints, is that they work at a distance.

Anyone with a phone can take a picture for facial-recognition programs to use.

FindFace, an app in Russia, compares snaps of strangers with pictures on VKontakte, a social network, and can identify people with a 70% accuracy rate.

Facebook's bank of facial images cannot be scraped by others, but the Silicon Valley giant could obtain pictures of visitors to a car showroom, say, and later use facial recognition to serve them ads for cars.

Even if private firms are unable to join the dots between images and identity, the state often can.

China's government keeps a record of its citizens' faces; photographs of half of America's adult population are stored in databases that can be used by the FBI.

Law-enforcement agencies now have a powerful weapon in their ability to track criminals, but at enormous potential cost to citizens' privacy.

The face is not just a name-tag.

It displays a lot of other information—and machines can read that, too.

Again, that promises benefits.

Some firms are analysing faces to provide automated diagnoses of rare genetic conditions, such as Hajdu-Cheney syndrome, far earlier than would otherwise be possible.

Systems that measure emotion may give autistic people a grasp of social signals they find elusive.